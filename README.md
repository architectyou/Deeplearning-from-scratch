# Deeplearning from scratch

Deep learning skills from scratch
딥러닝 기초 지식들을 위해 공부한 레포지토리입니다.

<br/>
<br/>

# Deeplearning Paper Reviews
| idx | Task | Keyword | Title | Author | Link | Review Link | Code Review |
|-----|------|---------|-------|--------|------|-------------|-------------|
|1|NLP|Attention, Transformer|Attention is all you need|Google|[Paper](https://arxiv.org/abs/1706.03762v7)|[Blog](https://zero-ai.tistory.com/36)|[Code](transformer.py)|
|2|NLP|BERT|Pre-training of Deep Bidirectional Transformers for Language Understatnding|Google AI Language|[Paper](https://arxiv.org/abs/1810.04805)|[Blog](https://zero-ai.tistory.com/52)||
|3|LLM|RAG|Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks|Facebook AI Research|[Paper](https://arxiv.org/abs/2005.11401)|[Blog](https://zero-ai.tistory.com/3)||
|4|LLM|Agent, LLM|Augmented Language Models|Facebook AI Research|[Paper](https://arxiv.org/abs/2302.07842)|[Blog](https://zero-ai.tistory.com/26)||
|5|LLM|MoE, SMoE|Mixtral of Experts|Mistral AI|[Paper](https://arxiv.org/pdf/2401.04088)|[Blog](https://zero-ai.tistory.com/51)||
|6|LLM|LoRA(PEFT)|Low-Rank Adaptation of LLM||[Paper](https://arxiv.org/pdf/2106.09685)|[Blog](https://zero-ai.tistory.com/56)||
|7|LLM|HyDE|Precise Zero-shot Dense Retriever without Relevance labels||[Paper](https://arxiv.org/abs/2212.10496)|[Blog](https://zero-ai.tistory.com/59)||